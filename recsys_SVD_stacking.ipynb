{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "# import geopandas as gpd\n",
    "# import geoplot as gplt\n",
    "from shapely.geometry import Point\n",
    "import shapely\n",
    "import reverse_geocoder as rg\n",
    "\n",
    "import sklearn as sk\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(13.7,10.27)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_color_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import dask\n",
    "\n",
    "from ast import literal_eval\n",
    "from collections.abc import MutableMapping\n",
    "from collections import Counter, defaultdict\n",
    "# import h5py\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import BaselineOnly\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection.split import train_test_split\n",
    "from surprise.model_selection import cross_validate, GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, io\n",
    "from surprise import KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline\n",
    "from surprise import SVDpp, SVD, NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "from surprise import accuracy\n",
    "from sklearn.linear_model import Ridge, RidgeCV, SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLENDER_RIDGE = \"RidgeCV\"\n",
    "BLENDER_SGD = \"SGDRegressor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:34469</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>33.65 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:34469' processes=8 threads=16, memory=33.65 GB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client = Client(n_workers=8)\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'reviewerName', 'categories', 'gPlusPlaceId', 'gPlusUserId',\n",
       "       'user_lat', 'user_long', 'placeName', 'price', 'address', 'place_lat',\n",
       "       'place_long'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df = dd.read_csv('data/joined_df.csv').compute()\n",
    "joined_df = joined_df.loc[:, ~joined_df.columns.str.match('Unnamed')]\n",
    "joined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def places_filter(df, lat_l, lat_h, lon_l, lon_h):\n",
    "    return df[(lat_l <= df.place_lat ) & (df.place_lat <= lat_h) & (lon_l <= df.place_long) & (df.place_long <= lon_h)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 192 ms, sys: 14 ms, total: 206 ms\n",
      "Wall time: 199 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2285757, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "usa_df = places_filter(joined_df, 19.50139, 64.85694, -161.75583, -68.01197)\n",
    "usa_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Stacking for Collaborative filtering RecSys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1,5))  #invoke reader instance of surprise library\n",
    "data = Dataset.load_from_df(usa_df[['gPlusUserId','gPlusPlaceId','rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training set\n",
    "trainingSet, testSet = train_test_split(data, test_size=0.2, train_size=None, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training first layer for Stacking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_item_sim_option = {\n",
    "    'name': 'pearson',\n",
    "    'user_based': False\n",
    "}\n",
    "pearson_user_sim_option = {\n",
    "    'name': 'pearson',\n",
    "    'user_based': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_first_layer(algorithms, hparams, train_set, test_set):\n",
    "    trained_algorithms = []\n",
    "    performances = []\n",
    "    \n",
    "    for idx, algorithm in enumerate(algorithms):\n",
    "        print(\"{} training started\".format(idx+1))\n",
    "        configured_algorithm = algorithm(n_factors=hparams[idx][\"n_factors\"], n_epochs=hparams[idx][\"n_epochs\"], reg_all= hparams[idx][\"reg_all\"])\n",
    "        configured_algorithm.fit(train_set)\n",
    "        trained_algorithms.append(configured_algorithm)\n",
    "        performances.append(accuracy.rmse(configured_algorithm.test(test_set), verbose=True))\n",
    "    \n",
    "    return trained_algorithms, performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_first_layer(trained_algorithms, test_set):\n",
    "    return [\n",
    "        trained_algorithm.test(test_set)\n",
    "        for trained_algorithm in trained_algorithms\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_last_layer(trained_algorithms, train_set, blender_algorithm=BLENDER_RIDGE):\n",
    "    actual_trainingSet = [each for each in train_set.all_ratings()]\n",
    "    predictions_for_trainingSet = predict_first_layer(trained_algorithms, actual_trainingSet)\n",
    "    print(\"Generating predictions Complete !\")\n",
    "    \n",
    "    train_pred = [[each.est for each in prediction] for prediction in predictions_for_trainingSet]\n",
    "    train_true = [each.r_ui for each in predictions_for_trainingSet[0]]\n",
    "    \n",
    "    blender_train_X = np.column_stack(train_pred)\n",
    "    blender_train_y = train_true\n",
    "    print(\"Organizing data for Blender Complete !\")\n",
    "    \n",
    "    assert blender_train_X.shape[0] == len(blender_train_y), \"There's problem in dimension for training set\"\n",
    "    \n",
    "    blender = None\n",
    "    if blender_algorithm is BLENDER_RIDGE: blender = RidgeCV(cv=5)\n",
    "    elif blender_algorithm is BLENDER_SGD: blender = SGDRegressor(max_iter=5000)\n",
    "    print(\"Determination for Blender Algorithm Complete !\")    \n",
    "    \n",
    "    blender.fit(blender_train_X, blender_train_y)\n",
    "    print(\"Blender Training Complete !\")\n",
    "    return blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_last_layer(trained_algorithms, blender, userID, iid):\n",
    "    preds = [algo.predict(userID, iid) for algo in trained_algorithms]\n",
    "    blender_X = np.column_stack((pred.est for pred in preds))\n",
    "    return blender.predict(blender_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training started\n",
      "RMSE: 1.1041\n",
      "2 training started\n",
      "RMSE: 1.1018\n",
      "3 training started\n",
      "RMSE: 1.1031\n",
      "CPU times: user 3min 3s, sys: 2.03 s, total: 3min 5s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "algorithms = [SVD, SVD, SVD]\n",
    "hparams = [\n",
    "    {\n",
    "        \"n_factors\": 20,\n",
    "        \"n_epochs\": 20,\n",
    "        \"reg_all\": 0.02\n",
    "    },\n",
    "    {\n",
    "        \"n_factors\": 30,\n",
    "        \"n_epochs\": 30,\n",
    "        \"reg_all\": 0.02\n",
    "    },\n",
    "    {\n",
    "        \"n_factors\": 40,\n",
    "        \"n_epochs\": 40,\n",
    "        \"reg_all\": 0.02\n",
    "    }\n",
    "]\n",
    "trained_algorithms, performances = train_first_layer(algorithms, hparams, trainingSet, testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_first_layer(trained_algorithms, testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true = [each.r_ui for each in predictions[0]]\n",
    "test_pred = [[each.est for each in prediction] for prediction in predictions]\n",
    "blender_test_X = np.column_stack(test_pred)\n",
    "blender_test_y = test_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1041362280847715\n",
      "1.101832985965809\n",
      "1.1031233851381275\n"
     ]
    }
   ],
   "source": [
    "# Sanity-Check for custom RMSE for Stacking\n",
    "for idx in range(3):\n",
    "    print(math.sqrt(mse(true, pred[idx]))) # RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Last layer, Blender, for Stacking !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions Complete !\n",
      "Organizing data for Blender Complete !\n",
      "Determination for Blender Algorithm Complete !\n",
      "Blender Training Complete !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1009706442546292"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blender = train_last_layer(trained_algorithms, trainingSet, BLENDER_SGD)\n",
    "final_pred = blender.predict(blender_test_X)\n",
    "math.sqrt(mse(final_pred, blender_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions Complete !\n",
      "Organizing data for Blender Complete !\n",
      "Determination for Blender Algorithm Complete !\n",
      "Blender Training Complete !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1736991631041538"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blender = train_last_layer(trained_algorithms, trainingSet, BLENDER_RIDGE)\n",
    "final_pred = blender.predict(blender_test_X)\n",
    "math.sqrt(mse(final_pred, blender_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find user-item pairs with no ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.05 s, sys: 25.4 ms, total: 2.08 s\n",
      "Wall time: 2.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainset = data.build_full_trainset()\n",
    "algo=SVD(n_factors=10,reg_all=0.01)\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "\n",
    "    lat1_r = radians(lat1)\n",
    "    lon1_r = radians(lon1)\n",
    "    lat2_r = radians(lat1)\n",
    "    lon2_r = radians(lon2)\n",
    "\n",
    "    dlon = lon2_r - lon1_r\n",
    "    dlat = lat2_r - lat1_r\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecommendations_from_df(df, userID='100000053212755369563', topN=3, lat=None, lon=None, distance_limit=100):\n",
    "    top_recs = defaultdict(list)\n",
    "    output_dict = {}\n",
    "    dis = None\n",
    "    for row in df.itertuples():\n",
    "        iid = row.gPlusPlaceId\n",
    "        predicted_value = algo.predict(userID, iid)\n",
    "        if lat and lon:\n",
    "            try:\n",
    "                dis = calculate_distance(row.place_lat, row.place_long, lat, lon)\n",
    "            except Exception as e:\n",
    "                  pass\n",
    "        if dis <= distance_limit:\n",
    "            top_recs[iid].append({'PlaceName':row.placeName, 'Distance':dis, 'Category':row.categories, 'Prediction':predicted_value.est})\n",
    "     \n",
    "    for iid, item_ratings in sorted(top_recs.items(), key=lambda item: (item[1][0].get('Prediction'), item[1][0].get('Distance')), reverse=True):\n",
    "        output_dict[iid]=item_ratings\n",
    "     \n",
    "    return output_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "CPU times: user 109 ms, sys: 9.35 ms, total: 118 ms\n",
      "Wall time: 91.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'110040354606321397134': [{'PlaceName': 'New Asian Restaurant',\n",
       "   'Distance': 0.1560081344773754,\n",
       "   'Category': \"['Asian Restaurant']\",\n",
       "   'Prediction': 3.437684978048763}],\n",
       " '103770440322838225806': [{'PlaceName': 'Franz Bakery Outlet Store',\n",
       "   'Distance': 0.27501351859849166,\n",
       "   'Category': \"['Bakery']\",\n",
       "   'Prediction': 3.157654664834565}],\n",
       " '109420033090810328045': [{'PlaceName': 'Firehouse Pizza',\n",
       "   'Distance': 0.08141167410460685,\n",
       "   'Category': \"['European Restaurant', 'Italian Restaurant', 'Pizza Restaurant']\",\n",
       "   'Prediction': 3.01128192116214}],\n",
       " '106591714648856494903': [{'PlaceName': 'Peking Chinese Restaurant',\n",
       "   'Distance': 2.2331361724487817e-12,\n",
       "   'Category': \"['Asian Restaurant', 'Chinese Restaurant']\",\n",
       "   'Prediction': 2.971059380024141}],\n",
       " '101530031206675973002': [{'PlaceName': 'Kenmore Lanes',\n",
       "   'Distance': 0.13456006148815874,\n",
       "   'Category': \"['Bowling Alley', 'Lounge', 'Restaurant']\",\n",
       "   'Prediction': 2.6280560689843084}]}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "recs= getRecommendations_from_df(usa_df[:10000], userID='118446742455312620560', lat=40.179159, lon=-122.236162, distance_limit= 0.5)\n",
    "print(len(recs.items()))\n",
    "recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecommendations_from_df_Blender(df, userID='100000053212755369563', topN=3, lat=None, lon=None, distance_limit=100):\n",
    "    top_recs = defaultdict(list)\n",
    "    output_dict = {}\n",
    "    dis = None\n",
    "    for row in df.itertuples():\n",
    "        iid = row.gPlusPlaceId\n",
    "#         predicted_value = algo.predict(userID, iid)\n",
    "        predicted_value = predict_last_layer(trained_algorithms, blender, userID, iid) # For Blender\n",
    "        if lat and lon:\n",
    "            try:\n",
    "                dis = calculate_distance(row.place_lat, row.place_long, lat, lon)\n",
    "            except Exception as e:\n",
    "                  pass\n",
    "#                 print(\"Exception caught: {}\".format(e))\n",
    "        if dis <= distance_limit:\n",
    "#             top_recs[iid].append({'PlaceName':row.placeName, 'Distance':dis, 'Category':row.categories, 'Prediction':predicted_value.est})\n",
    "            top_recs[iid].append({'PlaceName':row.placeName, 'Distance':dis, 'Category':row.categories, 'Prediction':predicted_value}) # For Blender\n",
    "     \n",
    "    for iid, item_ratings in sorted(top_recs.items(), key=lambda item: (item[1][0].get('Prediction'), item[1][0].get('Distance')), reverse=True):\n",
    "        output_dict[iid]=item_ratings\n",
    "     \n",
    "    return output_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "CPU times: user 1.01 s, sys: 101 ms, total: 1.11 s\n",
      "Wall time: 995 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'103770440322838225806': [{'PlaceName': 'Franz Bakery Outlet Store',\n",
       "   'Distance': 0.27501351859849166,\n",
       "   'Category': \"['Bakery']\",\n",
       "   'Prediction': array([3.96850495])}],\n",
       " '110040354606321397134': [{'PlaceName': 'New Asian Restaurant',\n",
       "   'Distance': 0.1560081344773754,\n",
       "   'Category': \"['Asian Restaurant']\",\n",
       "   'Prediction': array([3.96850495])}],\n",
       " '101530031206675973002': [{'PlaceName': 'Kenmore Lanes',\n",
       "   'Distance': 0.13456006148815874,\n",
       "   'Category': \"['Bowling Alley', 'Lounge', 'Restaurant']\",\n",
       "   'Prediction': array([3.96850495])}],\n",
       " '109420033090810328045': [{'PlaceName': 'Firehouse Pizza',\n",
       "   'Distance': 0.08141167410460685,\n",
       "   'Category': \"['European Restaurant', 'Italian Restaurant', 'Pizza Restaurant']\",\n",
       "   'Prediction': array([3.96850495])}],\n",
       " '106591714648856494903': [{'PlaceName': 'Peking Chinese Restaurant',\n",
       "   'Distance': 2.2331361724487817e-12,\n",
       "   'Category': \"['Asian Restaurant', 'Chinese Restaurant']\",\n",
       "   'Prediction': array([3.96850495])}]}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "recs= getRecommendations_from_df_Blender(usa_df[:10000], userID='118446742455312620560', lat=40.179159, lon=-122.236162, distance_limit= 0.5)\n",
    "print(len(recs.items()))\n",
    "recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmpe256-team4",
   "language": "python",
   "name": "cmpe256-team4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
