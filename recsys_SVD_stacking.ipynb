{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "# import geopandas as gpd\n",
    "# import geoplot as gplt\n",
    "from shapely.geometry import Point\n",
    "import shapely\n",
    "import reverse_geocoder as rg\n",
    "\n",
    "import sklearn as sk\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(13.7,10.27)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_color_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import dask\n",
    "\n",
    "from ast import literal_eval\n",
    "from collections.abc import MutableMapping\n",
    "from collections import Counter, defaultdict\n",
    "# import h5py\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import BaselineOnly\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection.split import train_test_split\n",
    "from surprise.model_selection import cross_validate, GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, io\n",
    "from surprise import KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline\n",
    "from surprise import SVDpp, SVD, NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "from surprise import accuracy\n",
    "from sklearn.linear_model import Ridge, RidgeCV, SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLENDER_RIDGE = \"RidgeCV\"\n",
    "BLENDER_SGD = \"SGDRegressor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:34469</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>33.65 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:34469' processes=8 threads=16, memory=33.65 GB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client = Client(n_workers=8)\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'reviewerName', 'categories', 'gPlusPlaceId', 'gPlusUserId',\n",
       "       'user_lat', 'user_long', 'placeName', 'price', 'address', 'place_lat',\n",
       "       'place_long'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df = dd.read_csv('data/joined_df.csv').compute()\n",
    "joined_df = joined_df.loc[:, ~joined_df.columns.str.match('Unnamed')]\n",
    "joined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def places_filter(df, lat_l, lat_h, lon_l, lon_h):\n",
    "    return df[(lat_l <= df.place_lat ) & (df.place_lat <= lat_h) & (lon_l <= df.place_long) & (df.place_long <= lon_h)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 198 ms, sys: 12.1 ms, total: 210 ms\n",
      "Wall time: 209 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2285757, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "usa_df = places_filter(joined_df, 19.50139, 64.85694, -161.75583, -68.01197)\n",
    "usa_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Stacking for Collaborative filtering RecSys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1,5))  #invoke reader instance of surprise library\n",
    "data = Dataset.load_from_df(usa_df[['gPlusUserId','gPlusPlaceId','rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training set\n",
    "trainingSet, testSet = train_test_split(data, test_size=0.2, train_size=None, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training first layer for Stacking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_item_sim_option = {\n",
    "    'name': 'pearson',\n",
    "    'user_based': False\n",
    "}\n",
    "pearson_user_sim_option = {\n",
    "    'name': 'pearson',\n",
    "    'user_based': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_first_layer(algorithms, hparams, train_set, test_set):\n",
    "    trained_algorithms = []\n",
    "    performances = []\n",
    "    \n",
    "    for idx, algorithm in enumerate(algorithms):\n",
    "        print(\"{} training started\".format(idx+1))\n",
    "        configured_algorithm = algorithm(n_factors=hparams[idx][\"n_factors\"], n_epochs=hparams[idx][\"n_epochs\"], reg_all= hparams[idx][\"reg_all\"])\n",
    "        configured_algorithm.fit(train_set)\n",
    "        trained_algorithms.append(configured_algorithm)\n",
    "        performances.append(accuracy.rmse(configured_algorithm.test(test_set), verbose=True))\n",
    "    \n",
    "    return trained_algorithms, performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_first_layer(trained_algorithms, test_set):\n",
    "    return [\n",
    "        trained_algorithm.test(test_set)\n",
    "        for trained_algorithm in trained_algorithms\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_last_layer(trained_algorithms, train_set, blender_algorithm=BLENDER_RIDGE):\n",
    "    actual_trainingSet = [each for each in train_set.all_ratings()]\n",
    "    predictions_for_trainingSet = predict_first_layer(trained_algorithms, actual_trainingSet)\n",
    "    print(\"Generating predictions Complete !\")\n",
    "    \n",
    "    train_pred = [[each.est for each in prediction] for prediction in predictions_for_trainingSet]\n",
    "    train_true = [each.r_ui for each in predictions_for_trainingSet[0]]\n",
    "    \n",
    "    blender_train_X = np.column_stack(train_pred)\n",
    "    blender_train_y = train_true\n",
    "    print(\"Organizing data for Blender Complete !\")\n",
    "    \n",
    "    assert blender_train_X.shape[0] == len(blender_train_y), \"There's problem in dimension for training set\"\n",
    "    \n",
    "    blender = None\n",
    "    if blender_algorithm is BLENDER_RIDGE: blender = RidgeCV(cv=5)\n",
    "    elif blender_algorithm is BLENDER_SGD: blender = SGDRegressor(max_iter=5000)\n",
    "    print(\"Determination for Blender Algorithm Complete !\")    \n",
    "    \n",
    "    blender.fit(blender_train_X, blender_train_y)\n",
    "    print(\"Blender Training Complete !\")\n",
    "    return blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_last_layer(trained_algorithms, blender, userID, iid):\n",
    "    preds = [algo.predict(userID, iid) for algo in trained_algorithms]\n",
    "    blender_X = np.column_stack((pred.est for pred in preds))\n",
    "    return blender.predict(blender_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training started\n",
      "RMSE: 1.1040\n",
      "2 training started\n",
      "RMSE: 1.1015\n",
      "3 training started\n",
      "RMSE: 1.1025\n",
      "CPU times: user 2min 46s, sys: 889 ms, total: 2min 47s\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "algorithms = [SVD, SVD, SVD]\n",
    "hparams = [\n",
    "    {\n",
    "        \"n_factors\": 20,\n",
    "        \"n_epochs\": 20,\n",
    "        \"reg_all\": 0.02\n",
    "    },\n",
    "    {\n",
    "        \"n_factors\": 30,\n",
    "        \"n_epochs\": 30,\n",
    "        \"reg_all\": 0.02\n",
    "    },\n",
    "    {\n",
    "        \"n_factors\": 40,\n",
    "        \"n_epochs\": 40,\n",
    "        \"reg_all\": 0.02\n",
    "    }\n",
    "]\n",
    "trained_algorithms, performances = train_first_layer(algorithms, hparams, trainingSet, testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_first_layer(trained_algorithms, testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true = [each.r_ui for each in predictions[0]]\n",
    "test_pred = [[each.est for each in prediction] for prediction in predictions]\n",
    "blender_test_X = np.column_stack(test_pred)\n",
    "blender_test_y = test_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1040438028865809\n",
      "1.101474219640708\n",
      "1.1024602939957509\n"
     ]
    }
   ],
   "source": [
    "# Sanity-Check for custom RMSE for Stacking\n",
    "for idx in range(3):\n",
    "    print(math.sqrt(mse(test_true, test_pred[idx]))) # RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Last layer, Blender, for Stacking !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions Complete !\n",
      "Organizing data for Blender Complete !\n",
      "Determination for Blender Algorithm Complete !\n",
      "Blender Training Complete !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1015450324207219"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_blender = train_last_layer(trained_algorithms, trainingSet, BLENDER_SGD)\n",
    "final_pred = SGD_blender.predict(blender_test_X)\n",
    "math.sqrt(mse(final_pred, blender_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions Complete !\n",
      "Organizing data for Blender Complete !\n",
      "Determination for Blender Algorithm Complete !\n",
      "Blender Training Complete !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1741878518117768"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RIDGE_blender = train_last_layer(trained_algorithms, trainingSet, BLENDER_RIDGE)\n",
    "final_pred = RIDGE_blender.predict(blender_test_X)\n",
    "math.sqrt(mse(final_pred, blender_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find user-item pairs with no ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.5 s, sys: 159 ms, total: 29.6 s\n",
      "Wall time: 29.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7ff594553ef0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainset = data.build_full_trainset()\n",
    "algo=SVD(n_factors=10,reg_all=0.01)\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(recs):\n",
    "    for gPlusPlaceID, values in recs.items():\n",
    "        dict_ = values[0]\n",
    "        print(dict_[\"PlaceName\"])\n",
    "        print(\"\\t Predicted Rating : {}\".format(dict_[\"Prediction\"]))\n",
    "        print(\"\\t Category : {}\".format(dict_[\"Category\"]))\n",
    "        print(\"\\t Distance : {}\".format(dict_[\"Distance\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "\n",
    "    lat1_r = radians(lat1)\n",
    "    lon1_r = radians(lon1)\n",
    "    lat2_r = radians(lat1)\n",
    "    lon2_r = radians(lon2)\n",
    "\n",
    "    dlon = lon2_r - lon1_r\n",
    "    dlat = lat2_r - lat1_r\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Algorithm Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecommendations_from_df(df, userID='100000053212755369563', topN=3, lat=None, lon=None, distance_limit=100):\n",
    "    top_recs = defaultdict(list)\n",
    "    output_dict = {}\n",
    "    dis = None\n",
    "    for row in df.itertuples():\n",
    "        iid = row.gPlusPlaceId\n",
    "        predicted_value = algo.predict(userID, iid)\n",
    "        if lat and lon:\n",
    "            try:\n",
    "                dis = calculate_distance(row.place_lat, row.place_long, lat, lon)\n",
    "            except Exception as e:\n",
    "                  pass\n",
    "        if dis <= distance_limit:\n",
    "            top_recs[iid].append({'PlaceName':row.placeName, 'Distance':dis, 'Category':row.categories, 'Prediction':predicted_value.est})\n",
    "     \n",
    "    for iid, item_ratings in sorted(top_recs.items(), key=lambda item: (item[1][0].get('Prediction'), item[1][0].get('Distance')), reverse=True):\n",
    "        output_dict[iid]=item_ratings\n",
    "     \n",
    "    return output_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "New Asian Restaurant\n",
      "\t Predicted Rating : 3.3479161607844534\n",
      "\t Category : ['Asian Restaurant']\n",
      "\t Distance : 0.1560081344773754\n",
      "Franz Bakery Outlet Store\n",
      "\t Predicted Rating : 3.1924162664889133\n",
      "\t Category : ['Bakery']\n",
      "\t Distance : 0.27501351859849166\n",
      "Firehouse Pizza\n",
      "\t Predicted Rating : 2.9707706616901874\n",
      "\t Category : ['European Restaurant', 'Italian Restaurant', 'Pizza Restaurant']\n",
      "\t Distance : 0.08141167410460685\n",
      "Peking Chinese Restaurant\n",
      "\t Predicted Rating : 2.9200316143704685\n",
      "\t Category : ['Asian Restaurant', 'Chinese Restaurant']\n",
      "\t Distance : 2.2331361724487817e-12\n",
      "Kenmore Lanes\n",
      "\t Predicted Rating : 2.7435379843215677\n",
      "\t Category : ['Bowling Alley', 'Lounge', 'Restaurant']\n",
      "\t Distance : 0.13456006148815874\n",
      "CPU times: user 86 ms, sys: 24.1 ms, total: 110 ms\n",
      "Wall time: 84 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recs= getRecommendations_from_df(usa_df[:10000], userID='118446742455312620560', lat=40.179159, lon=-122.236162, distance_limit= 0.5)\n",
    "print(len(recs.items()))\n",
    "print_result(recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC Stacking with SGDRegressor rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecommendations_from_df_Blender(df, userID='100000053212755369563', topN=3, lat=None, lon=None, distance_limit=100):\n",
    "    top_recs = defaultdict(list)\n",
    "    output_dict = {}\n",
    "    dis = None\n",
    "    for row in df.itertuples():\n",
    "        iid = row.gPlusPlaceId\n",
    "#         predicted_value = algo.predict(userID, iid)\n",
    "        predicted_value = predict_last_layer(trained_algorithms, SGD_blender, userID, iid) # For Blender\n",
    "        if lat and lon:\n",
    "            try:\n",
    "                dis = calculate_distance(row.place_lat, row.place_long, lat, lon)\n",
    "            except Exception as e:\n",
    "                  pass\n",
    "#                 print(\"Exception caught: {}\".format(e))\n",
    "        if dis <= distance_limit:\n",
    "#             top_recs[iid].append({'PlaceName':row.placeName, 'Distance':dis, 'Category':row.categories, 'Prediction':predicted_value.est})\n",
    "            top_recs[iid].append({'PlaceName':row.placeName, 'Distance':dis, 'Category':row.categories, 'Prediction':predicted_value[0]}) # For Blender\n",
    "     \n",
    "    for iid, item_ratings in sorted(top_recs.items(), key=lambda item: (item[1][0].get('Prediction'), item[1][0].get('Distance')), reverse=True):\n",
    "        output_dict[iid]=item_ratings\n",
    "     \n",
    "    return output_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "New Asian Restaurant\n",
      "\t Predicted Rating : 3.4839027972151326\n",
      "\t Category : ['Asian Restaurant']\n",
      "\t Distance : 0.1560081344773754\n",
      "Firehouse Pizza\n",
      "\t Predicted Rating : 3.2788416954367543\n",
      "\t Category : ['European Restaurant', 'Italian Restaurant', 'Pizza Restaurant']\n",
      "\t Distance : 0.08141167410460685\n",
      "Franz Bakery Outlet Store\n",
      "\t Predicted Rating : 3.127183936909595\n",
      "\t Category : ['Bakery']\n",
      "\t Distance : 0.27501351859849166\n",
      "Kenmore Lanes\n",
      "\t Predicted Rating : 3.0308978075253283\n",
      "\t Category : ['Bowling Alley', 'Lounge', 'Restaurant']\n",
      "\t Distance : 0.13456006148815874\n",
      "Peking Chinese Restaurant\n",
      "\t Predicted Rating : 2.9836454419031084\n",
      "\t Category : ['Asian Restaurant', 'Chinese Restaurant']\n",
      "\t Distance : 2.2331361724487817e-12\n",
      "CPU times: user 949 ms, sys: 48.6 ms, total: 997 ms\n",
      "Wall time: 919 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recs= getRecommendations_from_df_Blender(usa_df[:10000], userID='118446742455312620560', lat=40.179159, lon=-122.236162, distance_limit= 0.5)\n",
    "print(len(recs.items()))\n",
    "print_result(recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC Stacking with L2 Regression rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecommendations_from_df_Blender(df, userID='100000053212755369563', topN=3, lat=None, lon=None, distance_limit=100):\n",
    "    top_recs = defaultdict(list)\n",
    "    output_dict = {}\n",
    "    dis = None\n",
    "    for row in df.itertuples():\n",
    "        iid = row.gPlusPlaceId\n",
    "#         predicted_value = algo.predict(userID, iid)\n",
    "        predicted_value = predict_last_layer(trained_algorithms, RIDGE_blender, userID, iid) # For Blender\n",
    "        if lat and lon:\n",
    "            try:\n",
    "                dis = calculate_distance(row.place_lat, row.place_long, lat, lon)\n",
    "            except Exception as e:\n",
    "                  pass\n",
    "#                 print(\"Exception caught: {}\".format(e))\n",
    "        if dis <= distance_limit:\n",
    "#             top_recs[iid].append({'PlaceName':row.placeName, 'Distance':dis, 'Category':row.categories, 'Prediction':predicted_value.est})\n",
    "            top_recs[iid].append({'PlaceName':row.placeName, 'Distance':dis, 'Category':row.categories, 'Prediction':predicted_value[0]}) # For Blender\n",
    "     \n",
    "    for iid, item_ratings in sorted(top_recs.items(), key=lambda item: (item[1][0].get('Prediction'), item[1][0].get('Distance')), reverse=True):\n",
    "        output_dict[iid]=item_ratings\n",
    "     \n",
    "    return output_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Franz Bakery Outlet Store\n",
      "\t Predicted Rating : 3.969011350182243\n",
      "\t Category : ['Bakery']\n",
      "\t Distance : 0.27501351859849166\n",
      "New Asian Restaurant\n",
      "\t Predicted Rating : 3.969011350182243\n",
      "\t Category : ['Asian Restaurant']\n",
      "\t Distance : 0.1560081344773754\n",
      "Kenmore Lanes\n",
      "\t Predicted Rating : 3.969011350182243\n",
      "\t Category : ['Bowling Alley', 'Lounge', 'Restaurant']\n",
      "\t Distance : 0.13456006148815874\n",
      "Firehouse Pizza\n",
      "\t Predicted Rating : 3.969011350182243\n",
      "\t Category : ['European Restaurant', 'Italian Restaurant', 'Pizza Restaurant']\n",
      "\t Distance : 0.08141167410460685\n",
      "Peking Chinese Restaurant\n",
      "\t Predicted Rating : 3.969011350182243\n",
      "\t Category : ['Asian Restaurant', 'Chinese Restaurant']\n",
      "\t Distance : 2.2331361724487817e-12\n",
      "CPU times: user 889 ms, sys: 44.6 ms, total: 934 ms\n",
      "Wall time: 864 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recs= getRecommendations_from_df_Blender(usa_df[:10000], userID='118446742455312620560', lat=40.179159, lon=-122.236162, distance_limit= 0.5)\n",
    "print(len(recs.items()))\n",
    "print_result(recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note that L2's predictions hardly vary due to its regularzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmpe256-team4",
   "language": "python",
   "name": "cmpe256-team4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
