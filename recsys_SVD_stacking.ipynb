{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "# import geopandas as gpd\n",
    "# import geoplot as gplt\n",
    "from shapely.geometry import Point\n",
    "import shapely\n",
    "import reverse_geocoder as rg\n",
    "\n",
    "import sklearn as sk\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(13.7,10.27)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_color_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import dask\n",
    "\n",
    "from ast import literal_eval\n",
    "from collections.abc import MutableMapping\n",
    "from collections import Counter, defaultdict\n",
    "# import h5py\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import BaselineOnly\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection.split import train_test_split\n",
    "from surprise.model_selection import cross_validate, GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, io\n",
    "from surprise import KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline\n",
    "from surprise import SVDpp, SVD, NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "from surprise import accuracy\n",
    "from sklearn.linear_model import Ridge, RidgeCV, SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVD_ALGO = \"SVD\"\n",
    "BLENDER_RIDGE = \"RidgeCV\"\n",
    "BLENDER_SGD = \"SGDRegressor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ej/github/cmpe256-team4/cmpe256-team4/lib/python3.6/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 39341 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:35549</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:39341/status' target='_blank'>http://127.0.0.1:39341/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>33.65 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:35549' processes=8 threads=16, memory=33.65 GB>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(n_workers=8)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'reviewerName', 'categories', 'gPlusPlaceId', 'gPlusUserId',\n",
       "       'user_lat', 'user_long', 'placeName', 'price', 'address', 'place_lat',\n",
       "       'place_long'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df = dd.read_csv('data/joined_df.csv').compute()\n",
    "joined_df = joined_df.loc[:, ~joined_df.columns.str.match('Unnamed')]\n",
    "joined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def places_filter(df, lat_l, lat_h, lon_l, lon_h):\n",
    "    return df[(lat_l <= df.place_lat ) & (df.place_lat <= lat_h) & (lon_l <= df.place_long) & (df.place_long <= lon_h)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 170 ms, sys: 32.8 ms, total: 203 ms\n",
      "Wall time: 200 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2285757, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "usa_df = places_filter(joined_df, 19.50139, 64.85694, -161.75583, -68.01197)\n",
    "usa_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Stacking for Collaborative filtering RecSys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1,5))  #invoke reader instance of surprise library\n",
    "data = Dataset.load_from_df(usa_df[['gPlusUserId','gPlusPlaceId','rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training set\n",
    "trainingSet, testSet = train_test_split(data, test_size=0.2, train_size=None, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training first layer for Stacking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_item_sim_option = {\n",
    "    'name': 'pearson',\n",
    "    'user_based': False\n",
    "}\n",
    "pearson_user_sim_option = {\n",
    "    'name': 'pearson',\n",
    "    'user_based': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_first_layer(algorithms, hparams, train_set, test_set):\n",
    "    trained_algorithms = []\n",
    "    performances = []\n",
    "    \n",
    "    for idx, algorithm in enumerate(algorithms):\n",
    "        print(\"{} training started\".format(idx+1))\n",
    "        print(hparams[idx])\n",
    "        configured_algorithm = algorithm(n_factors=hparams[idx][\"n_factors\"], n_epochs=hparams[idx][\"n_epochs\"], reg_all= hparams[idx][\"reg_all\"])\n",
    "        configured_algorithm.fit(train_set)\n",
    "        trained_algorithms.append(configured_algorithm)\n",
    "        performances.append(accuracy.rmse(configured_algorithm.test(test_set), verbose=True))\n",
    "    \n",
    "    return trained_algorithms, performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_first_layer(trained_algorithms, test_set):\n",
    "    return [\n",
    "        trained_algorithm.test(test_set)\n",
    "        for trained_algorithm in trained_algorithms\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_last_layer(trained_algorithms, train_set, blender_algorithm=BLENDER_RIDGE):\n",
    "    actual_trainingSet = [each for each in train_set.all_ratings()]\n",
    "    predictions_for_trainingSet = predict_first_layer(trained_algorithms, actual_trainingSet)\n",
    "    print(\"Generating predictions Complete !\")\n",
    "    \n",
    "    train_pred = [[each.est for each in prediction] for prediction in predictions_for_trainingSet]\n",
    "    train_true = [each.r_ui for each in predictions_for_trainingSet[0]]\n",
    "    \n",
    "    blender_train_X = np.column_stack(train_pred)\n",
    "    blender_train_y = train_true\n",
    "    print(\"Organizing data for Blender Complete !\")\n",
    "    \n",
    "    assert blender_train_X.shape[0] == len(blender_train_y), \"There's problem in dimension for training set\"\n",
    "    \n",
    "    blender = None\n",
    "    if blender_algorithm is BLENDER_RIDGE: blender = RidgeCV(cv=5)\n",
    "    elif blender_algorithm is BLENDER_SGD: blender = SGDRegressor(max_iter=5000)\n",
    "    print(\"Determination for Blender Algorithm Complete !\")    \n",
    "    \n",
    "    blender.fit(blender_train_X, blender_train_y)\n",
    "    print(\"Blender Training Complete !\")\n",
    "    return blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_last_layer(trained_algorithms, blender, userID, iid):\n",
    "    preds = [algo.predict(userID, iid) for algo in trained_algorithms]\n",
    "    blender_X = np.column_stack((pred.est for pred in preds))\n",
    "    return blender.predict(blender_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training started\n",
      "{'n_factors': 20, 'n_epochs': 20, 'reg_all': 0.02}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-f3340fdda4e3>\u001b[0m in \u001b[0;36mtrain_first_layer\u001b[0;34m(algorithms, hparams, train_set, test_set)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} training started\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mconfigured_algorithm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_factors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_factors\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_all\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reg_all\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mconfigured_algorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtrained_algorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigured_algorithm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "algorithms = [SVD, SVD, SVD]\n",
    "hparams = [\n",
    "    {\n",
    "        \"n_factors\": 20,\n",
    "        \"n_epochs\": 20,\n",
    "        \"reg_all\": 0.02\n",
    "    },\n",
    "    {\n",
    "        \"n_factors\": 30,\n",
    "        \"n_epochs\": 30,\n",
    "        \"reg_all\": 0.02\n",
    "    },\n",
    "    {\n",
    "        \"n_factors\": 40,\n",
    "        \"n_epochs\": 40,\n",
    "        \"reg_all\": 0.02\n",
    "    }\n",
    "]\n",
    "trained_algorithms, performances = train_first_layer(algorithms, hparams, trainingSet, testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_first_layer(trained_algorithms, testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true = [each.r_ui for each in predictions[0]]\n",
    "test_pred = [[each.est for each in prediction] for prediction in predictions]\n",
    "blender_test_X = np.column_stack(test_pred)\n",
    "blender_test_y = test_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1041435036283367\n",
      "1.1014235174780553\n",
      "1.1023922315002417\n"
     ]
    }
   ],
   "source": [
    "# Sanity-Check for custom RMSE for Stacking\n",
    "for idx in range(3):\n",
    "    print(math.sqrt(mse(test_true, test_pred[idx]))) # RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Last layer, Blender, for Stacking !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions Complete !\n",
      "Organizing data for Blender Complete !\n",
      "Determination for Blender Algorithm Complete !\n",
      "Blender Training Complete !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1009622087229745"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_blender = train_last_layer(trained_algorithms, trainingSet, BLENDER_SGD)\n",
    "final_pred = SGD_blender.predict(blender_test_X)\n",
    "math.sqrt(mse(final_pred, blender_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions Complete !\n",
      "Organizing data for Blender Complete !\n",
      "Determination for Blender Algorithm Complete !\n",
      "Blender Training Complete !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1741878518117768"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RIDGE_blender = train_last_layer(trained_algorithms, trainingSet, BLENDER_RIDGE)\n",
    "final_pred = RIDGE_blender.predict(blender_test_X)\n",
    "math.sqrt(mse(final_pred, blender_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find user-item pairs with no ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.6 s, sys: 125 ms, total: 27.7 s\n",
      "Wall time: 27.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f24481016d8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainset = data.build_full_trainset()\n",
    "algo=SVD(n_factors=10,reg_all=0.01)\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(recs):\n",
    "    for gPlusPlaceID, values in recs.items():\n",
    "        dict_ = values[0]\n",
    "        print(dict_[\"PlaceName\"])\n",
    "        print(\"\\t Predicted Rating : {}\".format(dict_[\"Prediction\"]))\n",
    "        print(\"\\t Category : {}\".format(dict_[\"Category\"]))\n",
    "        print(\"\\t Distance : {}\".format(dict_[\"Distance\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "\n",
    "    lat1_r = radians(lat1)\n",
    "    lon1_r = radians(lon1)\n",
    "    lat2_r = radians(lat1)\n",
    "    lon2_r = radians(lon2)\n",
    "\n",
    "    dlon = lon2_r - lon1_r\n",
    "    dlat = lat2_r - lat1_r\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(trained_algorithms, userID, iid, algorithm):\n",
    "    if algorithm is SVD_ALGO: return algo.predict(userID, iid)\n",
    "    elif algorithm is BLENDER_RIDGE: return predict_last_layer(trained_algorithms, RIDGE_blender, userID, iid)\n",
    "    elif algorithm is BLENDER_SGD: return predict_last_layer(trained_algorithms, SGD_blender, userID, iid)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecommendations_from_df(df, userID='100000053212755369563', topN=3, lat=None, lon=None, distance_limit=100, algorithm=SVD_ALGO):\n",
    "    top_recs = defaultdict(list)\n",
    "    output_dict = {}\n",
    "    dis = None\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        iid = row.gPlusPlaceId\n",
    "        predicted_value = get_prediction(trained_algorithms, userID, iid, algorithm)\n",
    "        \n",
    "        if lat and lon:\n",
    "            try:\n",
    "                dis = calculate_distance(row.place_lat, row.place_long, lat, lon)\n",
    "            except Exception as e:\n",
    "                  pass\n",
    "        if dis <= distance_limit:\n",
    "            input_prediction = predicted_value.est if algorithm is SVD_ALGO else predicted_value[0]\n",
    "            top_recs[iid].append({'PlaceName':row.placeName, 'Distance':dis, 'Category':row.categories, 'Prediction': input_prediction})\n",
    "     \n",
    "    for iid, item_ratings in sorted(top_recs.items(), key=lambda item: (item[1][0].get('Prediction'), item[1][0].get('Distance')), reverse=True):\n",
    "        output_dict[iid]=item_ratings\n",
    "     \n",
    "    return output_dict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Algorithm Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "New Asian Restaurant\n",
      "\t Predicted Rating : 3.3635538441432797\n",
      "\t Category : ['Asian Restaurant']\n",
      "\t Distance : 0.1560081344773754\n",
      "Firehouse Pizza\n",
      "\t Predicted Rating : 3.1923502219609796\n",
      "\t Category : ['European Restaurant', 'Italian Restaurant', 'Pizza Restaurant']\n",
      "\t Distance : 0.08141167410460685\n",
      "Franz Bakery Outlet Store\n",
      "\t Predicted Rating : 3.033451393429345\n",
      "\t Category : ['Bakery']\n",
      "\t Distance : 0.27501351859849166\n",
      "Peking Chinese Restaurant\n",
      "\t Predicted Rating : 2.9408921255956106\n",
      "\t Category : ['Asian Restaurant', 'Chinese Restaurant']\n",
      "\t Distance : 2.2331361724487817e-12\n",
      "Kenmore Lanes\n",
      "\t Predicted Rating : 2.6797339185978095\n",
      "\t Category : ['Bowling Alley', 'Lounge', 'Restaurant']\n",
      "\t Distance : 0.13456006148815874\n",
      "CPU times: user 96.1 ms, sys: 15.3 ms, total: 111 ms\n",
      "Wall time: 85.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recs= getRecommendations_from_df(usa_df[:10000], userID='118446742455312620560', lat=40.179159, lon=-122.236162, distance_limit= 0.5, algorithm=SVD_ALGO)\n",
    "print(len(recs.items()))\n",
    "print_result(recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC Stacking with SGDRegressor rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "New Asian Restaurant\n",
      "\t Predicted Rating : 3.4837443795601324\n",
      "\t Category : ['Asian Restaurant']\n",
      "\t Distance : 0.1560081344773754\n",
      "Firehouse Pizza\n",
      "\t Predicted Rating : 3.1774137665314655\n",
      "\t Category : ['European Restaurant', 'Italian Restaurant', 'Pizza Restaurant']\n",
      "\t Distance : 0.08141167410460685\n",
      "Franz Bakery Outlet Store\n",
      "\t Predicted Rating : 3.1609283744914234\n",
      "\t Category : ['Bakery']\n",
      "\t Distance : 0.27501351859849166\n",
      "Kenmore Lanes\n",
      "\t Predicted Rating : 2.983262149281949\n",
      "\t Category : ['Bowling Alley', 'Lounge', 'Restaurant']\n",
      "\t Distance : 0.13456006148815874\n",
      "Peking Chinese Restaurant\n",
      "\t Predicted Rating : 2.9794438227443143\n",
      "\t Category : ['Asian Restaurant', 'Chinese Restaurant']\n",
      "\t Distance : 2.2331361724487817e-12\n",
      "CPU times: user 889 ms, sys: 96.7 ms, total: 986 ms\n",
      "Wall time: 897 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recs= getRecommendations_from_df(usa_df[:10000], userID='118446742455312620560', lat=40.179159, lon=-122.236162, distance_limit= 0.5, algorithm=BLENDER_SGD)\n",
    "print(len(recs.items()))\n",
    "print_result(recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC Stacking with L2 Regression rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Franz Bakery Outlet Store\n",
      "\t Predicted Rating : 3.969011350182243\n",
      "\t Category : ['Bakery']\n",
      "\t Distance : 0.27501351859849166\n",
      "New Asian Restaurant\n",
      "\t Predicted Rating : 3.969011350182243\n",
      "\t Category : ['Asian Restaurant']\n",
      "\t Distance : 0.1560081344773754\n",
      "Kenmore Lanes\n",
      "\t Predicted Rating : 3.969011350182243\n",
      "\t Category : ['Bowling Alley', 'Lounge', 'Restaurant']\n",
      "\t Distance : 0.13456006148815874\n",
      "Firehouse Pizza\n",
      "\t Predicted Rating : 3.969011350182243\n",
      "\t Category : ['European Restaurant', 'Italian Restaurant', 'Pizza Restaurant']\n",
      "\t Distance : 0.08141167410460685\n",
      "Peking Chinese Restaurant\n",
      "\t Predicted Rating : 3.969011350182243\n",
      "\t Category : ['Asian Restaurant', 'Chinese Restaurant']\n",
      "\t Distance : 2.2331361724487817e-12\n",
      "CPU times: user 887 ms, sys: 76.6 ms, total: 964 ms\n",
      "Wall time: 897 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recs= getRecommendations_from_df(usa_df[:10000], userID='118446742455312620560', lat=40.179159, lon=-122.236162, distance_limit= 0.5, algorithm=BLENDER_RIDGE)\n",
    "print(len(recs.items()))\n",
    "print_result(recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note that L2's predictions hardly vary due to its regularzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmpe256-team4",
   "language": "python",
   "name": "cmpe256-team4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
